# 基于clip的一个模型分类
## 参考项目 https://github.com/LAION-AI/CLIP-based-NSFW-Detector
    model可以自己任意改全连接
    主要做一些数据更新的一些事情，背景是实际nsfw数据集移植到业务时，很容易存在某些类型的大量的误识别
# 框架
## train 训练
## clip_data_augment 
    基于新的数据集查看clip结果，通过标注新增数据（主要是看正常图片是不是被分类为黄色）
    通过逐步标注训练来提高准确率
        先去小数据集，大概百万左右找出badcase（3k左右量级即可），更新数据集
        再增加数据集大小，再找出对应大小的badcase，再增加数据集训练
        最后再在一个自己的数据集上测试，可以千万级别左右的，可以下定一个准确率的结论
        这样可以快速有效的提升针对业务内容下，误识别率高的问题
        初步的话大概误识别可以从0.2%降到0.02%，让模型可用性提高